{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu1NODxh7ipW"
      },
      "source": [
        "# Multiple Linear Regression for Robot Calibration\n",
        "\n",
        "In this lab, we will illustrate the use of multiple linear regression for calibrating robot control.  In addition to reviewing the concepts in the multiple linear regression demo `demo_diabetes.ipynb`, you will see how to use multiple linear regression for time series data -- an important concept in dynamical systems such as robotics.\n",
        "\n",
        "The robot data for the lab is taken generously from the TU Dortmund's [Multiple Link Robot Arms Project](https://rst.etit.tu-dortmund.de/en/forschung/robotik/leichtbau/details-tudor/).  As part of the project, they have created an excellent public dataset: [MERIt](https://rst.etit.tu-dortmund.de/en/forschung/robotik/leichtbau/details-tudor/#c11560) -- A Multi-Elastic-Link Robot Identification Dataset that can be used for understanding robot dynamics.  The data is from a three link robot:\n",
        "\n",
        "<img src=\"https://rst.etit.tu-dortmund.de/storages/rst-etit/r/Media_Forschung/Robotik/Leichtbau/TUDORBild.png\" height=\"200\" width=\"200\">\n",
        "\n",
        "\n",
        "We will focus on predicting the current **electrical draw** into one of the joint motors as a function of the robot motion. This is just one of many parameters that you might want to build an ML model to predict.  For example, it might be part of a larger system to predict the overall robot power consumption."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijan3pKh7ipY"
      },
      "source": [
        "## Load and Visualize the Data\n",
        "First, import the modules we will need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lOtI0NEX7ipY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsiOAv4P7ipY"
      },
      "source": [
        "The full MERIt dataset can be obtained from the [MERIt site](https://rst.etit.tu-dortmund.de/en/forschung/robotik/leichtbau/details-tudor/#c11560).  But, this dataset is large.  Included in the course repository are two of the ten experiments.  Each experiments corresonds to 80 seconds of recorded motion.  We will use the following files:\n",
        "* [exp1.csv](https://github.com/cpmusco/machinelearning2022/blob/master/data/exp1.csv) for training\n",
        "* [exp2.csv](https://github.com/cpmusco/machinelearning2022/blob/master/data/exp2.csv) for test\n",
        "\n",
        "Below, I have supplied the column headers in the `names` array.  Use the `pd.read_csv` command to load the data. You may wich to refer to the first demo in the class where we used this fucntion. You can load the data directly from the following urls `https://github.com/cpmusco/machinelearning2022/blob/master/data/exp1.csv?raw=true` and `https://github.com/cpmusco/machinelearning2022/blob/master/data/exp2.csv?raw=true`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nHVbcdCU7ipY"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/6b/xsw_6vwj1vq3zrkmdy_fz6wh0000gn/T/ipykernel_57644/618899264.py:11: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  dftrain = pd.read_csv('https://github.com/cpmusco/machinelearning2022/blob/master/data/exp1.csv', header=None,delim_whitespace=False,names=names,na_values='?')\n"
          ]
        },
        {
          "ename": "ParserError",
          "evalue": "Error tokenizing data. C error: Expected 17 fields in line 42, saw 33\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m names \u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m'\u001b[39m,                                  \u001b[38;5;66;03m# Time (secs)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq3\u001b[39m\u001b[38;5;124m'\u001b[39m,                     \u001b[38;5;66;03m# Joint angle   (rads)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mddq1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mddq2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mddq3\u001b[39m\u001b[38;5;124m'\u001b[39m                \u001b[38;5;66;03m# Joint accelerations (rad/sec^2)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m ]\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# TODO\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m dftrain \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://github.com/cpmusco/machinelearning2022/blob/master/data/exp1.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mdelim_whitespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43mna_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m?\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m dftest \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://github.com/cpmusco/machinelearning2022/blob/master/data/exp2.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[0;32m~/WorkDir/Main Vault/Classes + Uni/Machine Learning/demos/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/WorkDir/Main Vault/Classes + Uni/Machine Learning/demos/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/WorkDir/Main Vault/Classes + Uni/Machine Learning/demos/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
            "File \u001b[0;32m~/WorkDir/Main Vault/Classes + Uni/Machine Learning/demos/.venv/lib/python3.13/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
            "File \u001b[0;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mparsers.pyx:2061\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 17 fields in line 42, saw 33\n"
          ]
        }
      ],
      "source": [
        "names =[\n",
        "    't',                                  # Time (secs)\n",
        "    'q1', 'q2', 'q3',                     # Joint angle   (rads)\n",
        "    'dq1', 'dq2', 'dq3',                  # Joint velocity (rads/sec)\n",
        "    'I1', 'I2', 'I3',                     # Motor current (amp)\n",
        "    'eps21', 'eps22', 'eps31', 'eps32',   # Strain gauge measurements ($\\mu$m /m )\n",
        "    'ddq1', 'ddq2', 'ddq3'                # Joint accelerations (rad/sec^2)\n",
        "]\n",
        "# TODO\n",
        "\n",
        "dftrain = pd.read_csv('https://github.com/cpmusco/machinelearning2022/blob/master/data/exp1.csv', header=None,delim_whitespace=False,names=names,na_values='?')\n",
        "dftest = pd.read_csv('https://github.com/cpmusco/machinelearning2022/blob/master/data/exp2.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLIhARhV7ipY"
      },
      "source": [
        "Print the first six lines of the test and train dataframes and manually check that they match the first rows of the csv file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwU2Nxpp7ipZ"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uv_Y2G-Q7ipZ"
      },
      "source": [
        "From the dataframe `dftrain`, extract the time values into a vector `t` and extract `I2`, the electrical current into the second joint. Place the electrical current in a vector `ytrain` and plot `ytrain` vs. `t`.   Label the axes with the units."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ey4oH7j47ipZ"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "# ytrain = ...\n",
        "# t = ...\n",
        "# plt.plot(...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkSI21Qi7ipa"
      },
      "source": [
        "Use all the samples from the experiment 1 dataset to create the training data:\n",
        "* `ytrain`:  A vector of all the samples from the `I2` column\n",
        "* `Xtrain`:  A matrix of the data with the columns:  `['q2','dq2','eps21', 'eps22', 'eps31', 'eps32','ddq2']`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrkUWNcr7ipa"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "# Xtrain = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flm1rdhw7ipb"
      },
      "source": [
        "## Fit a Linear Model\n",
        "Write an function that, fits a linear model given a predictor matrix `X` and a vector of target values `y`. Your linear model should have an intercept. So, for our robot data, which has 7 predictor variables, the output should be a vector `beta` of length 8. The first entry should be the intercept, $\\beta_0$. **Hint**: You might want to use numpy's `concatenate` function and the `ones` function.\n",
        "\n",
        "Your function should find the optimal `beta` to minimize the squared loss. You should do so using the matrix equations discussed in class -- do not use any built in functions from e.g. Scikit Learn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwTNlV1T7ipb"
      },
      "outputs": [],
      "source": [
        "def fit_mult_linear(X,y):\n",
        "    \"\"\"\n",
        "    Given matrix of predictors X and target vector y fit for a multiple linear regression model under the squared loss.\n",
        "    \"\"\"\n",
        "    # TODO complete the following code\n",
        "    # beta = ...\n",
        "    return beta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2LcZha87ipb"
      },
      "source": [
        "Train the model on the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kc8i_EOY7ipb"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "by3mu0j67ipb"
      },
      "source": [
        "Using the trained model, compute `ytrain_pred`, the predicted current.  Plot `ytrain_pred` vs. time `t`.  On the same plot, plot the actual current `ytrain` vs. time `t`.  Create a legend for the plot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4A2KU1p7ipb"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "# ytrain_pred = ...\n",
        "# plt.plot(...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRQMR2Au7ipc"
      },
      "source": [
        "## Measure the Fit on an Indepedent Dataset\n",
        "\n",
        "Up to now, we have only tested the model on the same data on which it was trained.  In general, we need to test models on independent data to truly understand the models quality -- otherwise, we might overfit.  For this purpose, consider the data loaded from `exp2.csv`.  Compute the regression predicted values on this data and plot the predicted and actual values over time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wqu4SYHW7ipc"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
