{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insult Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we would like to filter out insulting comments on a web forum. \n",
    "\n",
    "To train our models, we have a list of historic comments with a judgement wether they're insulting or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20120618192155Z</td>\n",
       "      <td>You fuck your dad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>20120528192215Z</td>\n",
       "      <td>i really don't understand your point.  It seem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Insult             Date                                            Comment\n",
       "0       1  20120618192155Z                                 You fuck your dad.\n",
       "1       0  20120528192215Z  i really don't understand your point.  It seem..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "path_to_insults = ''\n",
    "data = pd.read_csv(path_to_insults + 'train-utf8.csv')\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3947 comments, of which 1049 insults (26%)\n"
     ]
    }
   ],
   "source": [
    "print (\"%d comments, of which %d insults (%d%%)\" % \\\n",
    "    (len(data), data.Insult.sum(), 100 * data.Insult.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking for known bad words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to do this, is to load Google's bad word list and flag comments that contain one or more words.\n",
    "\n",
    "- Load `google_badlist.txt` from `data/insults/`\n",
    "- Add a column to `data` with a flag (0 or 1) if the comment contains a bad word\n",
    "- Compute the accuracy of this method - does this look good?\n",
    "- What would a naive classifier's score be (i.e., always predicting 0 or 1)?\n",
    "- Also compute the precision, recall, F1 score and AUC score\n",
    "- What is your verdict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'google_badlist.txt'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = path_to_insults + 'google_badlist.txt'\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "badlist = pd.read_csv('google_badlist.txt', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4r5e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5h1t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>whore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>willies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>willy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>xrated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>451 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0       4r5e\n",
       "1       5h1t\n",
       "2       5hit\n",
       "3        a55\n",
       "4       anal\n",
       "..       ...\n",
       "446    whore\n",
       "447  willies\n",
       "448    willy\n",
       "449   xrated\n",
       "450      xxx\n",
       "\n",
       "[451 rows x 1 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "badlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Contains Bad Word'] = data.Comment.apply(lambda x: any(w in x for w in badlist[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 65.59%\n",
      "I mean, anything better than 50% is good, right? We can do better though...\n"
     ]
    }
   ],
   "source": [
    "\"Accuracy is true positives + true negatives divided by total number of cases\"\n",
    "true_positives = data[(data.Insult == 1) & (data['Contains Bad Word'] == True)].shape[0]\n",
    "true_negatives = data[(data.Insult == 0) & (data['Contains Bad Word'] == False)].shape[0]\n",
    "false_positives = data[(data.Insult == 0) & (data['Contains Bad Word'] == True)].shape[0]\n",
    "false_negatives = data[(data.Insult == 1) & (data['Contains Bad Word'] == False)].shape[0]\n",
    "accuracy = (true_positives + true_negatives) / len(data)\n",
    "print(f\"Accuracy: {accuracy:.2%}\")\n",
    "print(\"I mean, anything better than 50% is good, right? We can do better though...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive classifier (always predicting 0): 73.42% accuracy\n",
      "Naive classifier (always predicting 1): 26.58% accuracy\n",
      "Ok, never mind, we can't do better than 50% accuracy. Let's just predict 1 all the time!!!\n"
     ]
    }
   ],
   "source": [
    "total = len(data)\n",
    "num_positive = true_positives + false_negatives\n",
    "num_negative = total - num_positive\n",
    "\n",
    "accuracy_pred0 = num_negative / total\n",
    "accuracy_pred1 = num_positive / total\n",
    "\n",
    "print(\"Naive classifier (always predicting 0): {:.2%} accuracy\".format(accuracy_pred0))\n",
    "print(\"Naive classifier (always predicting 1): {:.2%} accuracy\".format(accuracy_pred1))\n",
    "print(\"Ok, never mind, we can't do better than 50% accuracy. Let's just predict 1 all the time!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 37.59%\n",
      "Recall: 44.61%\n",
      "F1: 40.80%\n"
     ]
    }
   ],
   "source": [
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "print(f\"Precision: {precision:.2%}\")\n",
    "print(f\"Recall: {recall:.2%}\")\n",
    "print(f\"F1: {f1:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok, yes, this is bad.\n"
     ]
    }
   ],
   "source": [
    "print(\"Ok, yes, this is bad.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning bad words on the fly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of doing this, is to learn the insulting words on the fly using `CountVectorizer`. \n",
    "\n",
    "Please refer to the scikit learn tutorial at 'http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html' if you need some help.\n",
    "\n",
    "Here is what you need to do:\n",
    "\n",
    "- Import `CountVectorizer` from `sklearn.feature_extraction.text`\n",
    "- Train the `CountVectorizer` on the insults and create a feature set $X$ representing words in the comments\n",
    "- Train `MultinomialNB` and `BernoulliNB` from `scikitsklearn`  on the new feature set $X$\n",
    "- Using cross-validation, compute the accuracy, precision, recall, F1 and AUC of your model\n",
    "- What is your verdict?\n",
    "\n",
    "NOTE: The F1 score is another useful score to compute when one of the two classes is very rare. We didn't go over it in class but it's basically the harmonic mean between precision and recall and goes from 0 (min) to 1 (max).  You can see more here: 'https://en.wikipedia.org/wiki/F1_score' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
