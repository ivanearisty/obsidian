# General
Types of supervised earning:
- Classification – predict a discrete class label.
- Regression – predict a continuous value.
- Dependent variable, response variable, target variable, lots of diferent names for y

In supervised learnings every input x_i in our training dataset comes with a desired output y_i (typically generated by a human, or some other process).
# [[Simple Linear Regression]]

## Goodness of fit
![[z/z ScreenShots/Screenshot 2025-02-26 at 4.33.03 AM.jpg| 500]]
## Formulas
![[z/z ScreenShots/Screenshot 2025-03-11 at 6.52.51 PM.jpg| 500]]
## Non-linear model transformation

# [[Multiple Linear Regression]]

# [[Model Selection]]

Why consider alternatives to least squares?

- Prediction Accuracy: especially when d > n, to control the variance.
- Model Interpretability: By removing irrelevant features, that is, by setting the corresponding coe!cients to zero. We obtain a sparse model, which is easier to interpret.

Training loss alone is not usually a good metric for model selection. Small loss does not imply generalization.

![[z/z ScreenShots/Screenshot 2025-03-11 at 9.34.14 PM.jpg| 500]]

![[z/z ScreenShots/Screenshot 2025-03-11 at 9.34.46 PM.jpg| 500]]

Models which perform better on the test set will generalize better to future data.

![[z/z ScreenShots/Screenshot 2025-03-11 at 9.37.15 PM.jpg| 500]]

![[z/z ScreenShots/Screenshot 2025-03-11 at 9.38.32 PM.jpg| 500]]

Population risk, also known as the true risk, is the expected loss of a model over the entire input distribution. It is the average loss the model incurs across all possible data points.

Empirical risk is an estimate of the population risk based on a finite sample of data. It is the average loss over the training dataset.
![[z/z ScreenShots/Screenshot 2025-03-11 at 9.41.42 PM.jpg| 500]]

# [[Regularization]]
# Numpy and Pandas

## Inverse Transformation
